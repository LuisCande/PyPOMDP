# Inspired by Sondik's infinite-horizon paper
#

discount: 0.75
values: reward
states: interested bored
actions: tv radio nothing
observations: want-to-go dont-want-to-go
start: 0.9 0.1

# transition probabilities

T: tv : interested : interested 0.9
T: tv : interested : bored 0.1
T: tv : bored : interested 0.6
T: tv : bored : bored 0.4

T: radio : interested : interested 0.8
T: radio : interested : bored 0.2
T: radio : bored : interested 0.3
T: radio : bored : bored 0.7

T: nothing : interested : interested 0.5
T: nothing : interested : bored 0.5
T: nothing : bored : interested 0.1
T: nothing : bored : bored 0.9

# observations

O: tv : interested : want-to-go 0.8
O: tv : interested : dont-want-to-go 0.2
O: tv : bored : want-to-go 0.7
O: tv : bored : dont-want-to-go 0.3

O: radio : interested : want-to-go 0.7
O: radio : interested : dont-want-to-go 0.3
O: radio : bored : want-to-go 0.4
O: radio : bored : dont-want-to-go 0.6

O: nothing : interested : want-to-go 0.9
O: nothing : interested : dont-want-to-go 0.1
O: nothing : bored : want-to-go 0.1
O: nothing : bored : dont-want-to-go 0.9

# cost structure

R: tv : interested : * : * -10
R: tv : bored : * : * -10

R: radio : 1 : * : * -4
R: radio : 1 : * : * -4

R: nothing : interested : * : * 0
R: nothing : bored : * : * 0
